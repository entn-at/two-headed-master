#!/bin/bash

set -u

#
# This script creates an arpa language model with the MIT toolkit using as
# input a csv file as generated by process_exmaralda_xml.py.
#
# Parameters:
# - Input csv: csv file, with fields:
    # utt_id
    # transcription
    # normalized
    # speaker_id
    # audio_id
    # anonymity
    # speech_in_speech
    # missing_audio
    # no_relevant_speech
#
# - output_dir: output folder to write the language model and lexicon.
#
# Optional parameters:
# -o language model order
# -c clusters
# -t dieth OR norm

################
# Configuration:
################
scripts_dir=`dirname $0`
manual_dir=`readlink -m $scripts_dir/../manual`
clusters="$manual_dir/clusters.txt"
spn_word='<SPOKEN_NOISE>'
sil_word='<SIL_WORD>'
lm_order=3
exclude_symbols=1  # If not zero, exclude spn_word and sil_word from the model
transcription=orig # If not specified, dieth transcription is used as default

echo $0 $@
while getopts 'o:c:t:h' option; do
    case $option in
	o)
	    lm_order=${OPTARG}
	    ;;
	c)
	    clusters=${OPTARG}
	    ;;
	t)
	    transcription=${OPTARG}
	    ;;
	h)
	    echo "$0 [-o lm_order] [-c graphemic_clusters] [-t transcription_type] input_csv output_dir"
	    exit 0
	    ;;
	\?)
	    echo "Option not supported: -$OPTARG" >$2
	    exit 1
	    ;;
	:)
	    echo "Option -$OPTARG requires an argument." >&2
	    exit 1
	    ;;
    esac
done
shift $((OPTIND-1))

if [[ $# -ne 2 ]]; then
    echo "Wrong call. Should be: $0 [-o lm_order] [-c graphemic_clusters] [-t transcription_type] input_csv output_dir"
    exit 1
fi

##################
# Input arguments:
##################
input_csv=$1
output_dir=$2

#########
# Output:
#########
out_lm="$output_dir/language_model.arpa"

###############
# Intermediate:
###############
tmp_dir="$output_dir/tmp"
output_transcriptions="$tmp_dir/transcriptions.txt"
wav_lst="$tmp_dir/wav.lst"
utterances="$tmp_dir/utterances.txt"

# Check whether ffmpeg is installed:
type estimate-ngram &> /dev/null
[[ $? -ne 0 ]] && echo 'Error: the MIT toolkit is not installed' && exit 1

for f in $input_csv $clusters; do
    [[ ! -e $f ]] && echo "Error: missing file $f" && exit 1
done

mkdir -p $output_dir $tmp_dir

##
# 1.- Create the output transcriptions and wave list:
# Note the option -p: Archimob markers (hesitations, coughing, ...) are
# mapped to less specific classes (see process_archimob.csv.py)
echo "Processing $input_csv:"
$scripts_dir/process_archimob_csv.py \
-i $input_csv \
-p \
-trans $transcription \
-t $output_transcriptions \
-s $spn_word \
-n $sil_word \
-o $wav_lst

[[ $? -ne 0 ]] && echo 'Error calling process_archimob_csv.py' && exit 1

##
# 2.- Create the language model:
echo "Creating the language model: $out_lm"
cut -f 2 $output_transcriptions | perl -pe 's#(\s)+#\1#g' > $utterances

if [[ $exclude_symbols -ne 0 ]]; then
    export SPN=$spn_word
    export SIL=$sil_word
    mv $utterances $utterances.tmp
    perl -pe 's#$ENV{SPN}##g; s#$ENV{SIL}##g; s#(\s)+#\1#g; s#^\s+##; ' \
    $utterances.tmp > $utterances
fi

estimate-ngram -t $utterances -o $lm_order -wl $out_lm

[[ $? -ne 0 ]] && echo 'Error calling estimate-ngram' && exit 1

echo "Done: $0"
